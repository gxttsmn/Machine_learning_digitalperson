# 视频人像口型与语音匹配模型 - 完整操作流程

## 📋 项目概述

本项目用于训练一个本地可调用的垂类领域大模型，主要应用于**视频人像口型与语音匹配功能(数字人口播)**（Lip-Sync）。

## 🎯 完整操作流程（四步走）

### ✅ 第一步：环境准备（5-10分钟）

#### 1.1 检查Python版本
```bash
python --version
```
**要求：** Python 3.8-3.10

#### 1.2 创建虚拟环境（推荐）
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac  
python -m venv venv
source venv/bin/activate
```

#### 1.3 安装基础依赖
```bash
pip install -r requirements.txt
```

#### 1.4 安装PyTorch
**有NVIDIA GPU的用户：**
- 访问 https://pytorch.org/
- 选择你的CUDA版本，复制安装命令
- 例如（CUDA 11.8）：
  ```bash
  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
  ```

**仅CPU用户：**
```bash
pip install torch torchvision torchaudio
```

#### 1.5 创建项目目录结构
```bash
python setup_directories.py
```

**验证：** 检查以下目录是否创建成功：
- `data/videos/` - 存放原始视频
- `data/audios/` - 存放原始音频
- `data/processed/` - 存放处理后的数据
- `checkpoints/` - 存放模型检查点
- `logs/` - 存放训练日志
- `outputs/` - 存放输出结果

---

### ✅ 第二步：数据准备（30分钟-数小时）

#### 2.1 准备训练数据

**视频文件：**
- 放入 `data/videos/` 目录
- 格式：MP4, AVI等
- 要求：
  - ✅ 包含清晰的人脸正面图像
  - ✅ 视频长度：5-30秒（推荐）
  - ✅ 分辨率：至少320x240
  - ✅ 光线充足，人脸清晰可见

**音频文件：**
- 放入 `data/audios/` 目录
- 格式：WAV, MP3等
- 要求：
  - ✅ 与视频同步
  - ✅ 采样率：16kHz或更高
  - ✅ 清晰无杂音

**文件命名规则：**
- 视频和音频文件名必须对应
- 示例：
  - `video1.mp4` ↔ `video1.wav`
  - `person_talk.mp4` ↔ `person_talk.wav`

**数据量要求：**
- **最小：** 100个视频-音频对
- **推荐：** 500-1000个视频-音频对
- **最佳：** 1000+个视频-音频对

#### 2.2 运行数据预处理

```bash
python src/data_processing.py
```

**处理过程：**
1. 自动扫描 `data/videos/` 目录中的所有视频
2. 查找对应的音频文件
3. 使用人脸检测提取人脸区域
4. 提取音频MFCC特征
5. 对齐视频帧和音频特征
6. 保存处理后的数据到 `data/processed/`

**预期输出：**
```
找到 100 个视频文件
处理视频: 100%|████████████| 100/100 [05:23<00:00,  3.23s/it]

处理完成！共处理 95 个样本
数据保存在: data/processed
索引文件: data/processed/dataset_index.pkl
```

**常见问题处理：**
- ❌ "未检测到人脸" → 检查视频是否有人脸，光线是否充足
- ❌ "未找到对应的音频文件" → 检查文件名是否匹配
- ❌ 处理速度慢 → 正常，人脸检测需要时间

---

### ✅ 第三步：模型训练（数小时-数天）

#### 3.1 配置训练参数

编辑 `config.yaml` 文件：

```yaml
training:
  batch_size: 16        # 根据GPU内存调整
                        # 6GB显存: 8-16
                        # 8GB显存: 16-32
                        # CPU: 2-4
  num_epochs: 100       # 训练轮数，建议100-200
  learning_rate: 0.0001 # 学习率，可尝试0.0001, 0.001, 0.00001
  device: "cuda"        # "cuda" 或 "cpu"
```

#### 3.2 开始训练

```bash
python src/train.py
```

**训练过程说明：**
- 自动划分数据集：训练集80% / 验证集10% / 测试集10%
- 实时显示训练进度和损失
- 自动保存最佳模型：`checkpoints/best_model.pth`
- 每10个epoch保存检查点：`checkpoints/checkpoint_epoch_N.pth`

**预期输出：**
```
使用设备: cuda
模型参数数量: 2,345,678
加载了 95 个样本

开始训练...
训练样本: 76, 验证样本: 9, 测试样本: 10

Epoch 1/100
训练: 100%|████████████| 5/5 [01:23<00:00, 16.6s/it, loss=0.2341, acc=0.6500]
验证: 100%|████████████| 1/1 [00:05<00:00,  5.2s/it]
训练损失: 0.2341, 训练准确率: 0.6500
验证损失: 0.1892, 验证准确率: 0.7778
学习率: 0.000100
保存最佳模型: checkpoints/best_model.pth
```

**训练时间估算：**
- GPU (RTX 3060, 6GB): 约2-4小时/100个epoch
- GPU (RTX 3090, 24GB): 约1-2小时/100个epoch
- CPU: 可能需要数天

#### 3.3 监控训练（可选）

**启动TensorBoard：**
```bash
tensorboard --logdir logs
```

**查看训练曲线：**
- 浏览器打开：http://localhost:6006
- 可以查看：
  - 训练/验证损失曲线
  - 准确率曲线
  - 学习率变化

**停止训练：**
- 按 `Ctrl+C` 安全停止
- 已保存的模型可以直接使用

---

### ✅ 第四步：模型推理（几分钟）

#### 4.1 Python代码调用

**创建测试脚本 `test_inference.py`：**

```python
from src.inference import LipSyncInference

# 初始化推理器
inference = LipSyncInference(
    checkpoint_path="checkpoints/best_model.pth"
)

# 方法1: 计算同步分数
score, details = inference.compute_sync_score(
    video_path="test_video.mp4",
    audio_path="test_audio.wav"
)
print(f"同步分数: {score:.3f}")  # 0-1之间，越高越同步

# 方法2: 生成同步视频
success, message = inference.sync_video_audio(
    video_path="input_video.mp4",
    audio_path="input_audio.wav",
    output_path="output_synced.mp4"
)
print(message)
```

**运行：**
```bash
python test_inference.py
```

#### 4.2 命令行调用

**仅计算同步分数：**
```bash
python src/inference.py \
    --checkpoint checkpoints/best_model.pth \
    --video test_video.mp4 \
    --audio test_audio.wav \
    --score-only
```

**生成同步视频：**
```bash
python src/inference.py \
    --checkpoint checkpoints/best_model.pth \
    --video input_video.mp4 \
    --audio input_audio.wav \
    --output output_synced.mp4
```

#### 4.3 查看示例代码

查看 `example_usage.py` 了解更多使用示例：
- 计算同步分数
- 生成同步视频
- 批量处理

---

## 🔧 常见问题排查

### 问题1：CUDA out of memory
**症状：** 训练时提示显存不足

**解决方案：**
1. 减小 `batch_size`（在config.yaml中）
2. 减小 `input_size`（在config.yaml中，如96改为64）
3. 使用CPU训练（会很慢）

### 问题2：训练损失不下降
**症状：** 训练多个epoch后损失仍然很高

**可能原因：**
- 学习率不合适
- 数据质量不好
- 数据量太少

**解决方案：**
1. 调整学习率（尝试0.0001, 0.001, 0.00001）
2. 检查数据质量（视频是否清晰，音频是否同步）
3. 增加训练数据量（至少100个样本）

### 问题3：检测不到人脸
**症状：** 数据预处理时提示"未检测到人脸"

**解决方案：**
1. 确保视频中有清晰的人脸
2. 人脸应该正面朝向
3. 光线充足
4. 尝试不同的视频

### 问题4：模型效果不好
**症状：** 推理时同步分数很低

**改进方向：**
1. 增加训练数据量（至少1000个样本）
2. 提高数据质量（清晰、同步的视频-音频对）
3. 调整模型参数（增加hidden_dim, num_layers等）
4. 增加训练轮数（num_epochs）

---

## 📊 性能优化建议

### 提高模型性能
1. **增加模型容量**
   - 在config.yaml中增加 `hidden_dim`（如512→1024）
   - 增加 `num_layers`（如2→3）

2. **数据增强**
   - 随机裁剪
   - 随机翻转
   - 添加噪声

3. **更长的训练**
   - 增加 `num_epochs`（如100→200）

### 提高推理速度
1. **模型量化**
   - 使用torch.quantization量化模型

2. **批量推理**
   - 使用 `batch_process` 方法批量处理

3. **GPU加速**
   - 确保使用CUDA设备

---

## 📁 项目文件说明

```
Machine_learning/
├── config.yaml              # 配置文件（训练参数）
├── requirements.txt         # Python依赖包
├── README.md               # 项目说明文档
├── QUICK_START.md          # 快速开始指南
├── 操作流程总结.md          # 本文档
├── setup_directories.py     # 创建目录结构
├── example_usage.py        # 使用示例代码
│
├── src/                    # 源代码目录
│   ├── __init__.py
│   ├── data_processing.py  # 数据预处理模块
│   ├── model.py           # 模型定义
│   ├── train.py           # 训练脚本
│   └── inference.py       # 推理接口
│
├── data/                   # 数据目录
│   ├── videos/            # 原始视频文件
│   ├── audios/            # 原始音频文件
│   └── processed/         # 处理后的数据
│
├── checkpoints/            # 模型检查点
│   └── best_model.pth     # 最佳模型（训练后生成）
│
├── logs/                   # 训练日志（TensorBoard）
└── outputs/                # 输出结果
```

---

## 🎓 学习资源

### 相关技术
- **Lip-Sync技术：** 口型同步技术
- **MFCC特征：** 音频特征提取
- **人脸检测：** face_alignment库
- **深度学习：** PyTorch框架

### 进阶方向
1. **实时推理：** 优化模型推理速度
2. **多人脸检测：** 支持视频中多个人脸
3. **Transformer架构：** 使用更先进的模型架构
4. **数据增强：** 提高模型泛化能力

---

## ✅ 检查清单

在开始之前，确保：

- [ ] Python 3.8-3.10已安装
- [ ] 虚拟环境已创建并激活
- [ ] 所有依赖包已安装
- [ ] PyTorch已正确安装（GPU版本或CPU版本）
- [ ] 项目目录结构已创建
- [ ] 训练数据已准备（至少100个视频-音频对）
- [ ] 数据预处理已完成
- [ ] 配置文件已检查
- [ ] 准备开始训练

---

## 🚀 开始你的第一个模型训练！

按照上述四步流程，你现在可以：

1. ✅ 准备环境
2. ✅ 准备数据
3. ✅ 训练模型
4. ✅ 使用模型

**祝训练顺利！** 🎉

如有问题，请查看：
- `README.md` - 详细文档
- `QUICK_START.md` - 快速开始指南
- `example_usage.py` - 代码示例

